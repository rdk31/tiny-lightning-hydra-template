_target_: src.data.imagenet.ImageNetDataModule

num_classes: 1000
root: ${core.data_dir}/imagenet

train_transform:
  _target_: torchvision.transforms.v2.Compose
  transforms:
    - _target_: torchvision.transforms.v2.ToImage
    - _target_: torchvision.transforms.v2.ToDtype
      dtype:
        _target_: torch.__dict__.get # workaround, see: https://github.com/facebookresearch/hydra/issues/2140
        _args_:
          - float32
      scale: True
    - _target_: torchvision.transforms.v2.Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    - _target_: torchvision.transforms.v2.RandomCrop
      size: 224
      pad_if_needed: True

val_transform:
  _target_: torchvision.transforms.v2.Compose
  transforms:
    - _target_: torchvision.transforms.v2.ToImage
    - _target_: torchvision.transforms.v2.ToDtype
      dtype:
        _target_: torch.__dict__.get # workaround, see: https://github.com/facebookresearch/hydra/issues/2140
        _args_:
          - float32
      scale: True
    - _target_: torchvision.transforms.v2.Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    - _target_: torchvision.transforms.v2.CenterCrop
      size: 224

batch_size: 32
num_workers: 8
pin_memory: True
