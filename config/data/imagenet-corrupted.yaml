_target_: src.data.datamodule.DataModule

num_classes: 1000

train_dataset:
  _target_: src.data.corruptions.CorruptedDataset
  _partial_: True

  corruption:
    _target_: src.data.corruptions.LowResolution
    factor: 4

  dataset:
    _target_: src.data.imagenet.ImageNet

    root: ${core.data_dir}/imagenet
    split: train

    transform:
      _target_: torchvision.transforms.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.ToDtype
          dtype:
            _target_: torch.__dict__.get # workaround, see: https://github.com/facebookresearch/hydra/issues/2140
            _args_:
              - float32
          scale: True
        - _target_: torchvision.transforms.v2.RandomCrop
          size: 224
          pad_if_needed: True

val_dataset:
  _target_: src.data.corruptions.CorruptedDataset
  _partial_: True

  corruption:
    _target_: src.data.corruptions.LowResolution
    factor: 4

  dataset:
    _target_: src.data.imagenet.ImageNet

    root: ${core.data_dir}/imagenet
    split: val

    transform:
      _target_: torchvision.transforms.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.ToDtype
          dtype:
            _target_: torch.__dict__.get # workaround, see: https://github.com/facebookresearch/hydra/issues/2140
            _args_:
              - float32
          scale: True
        - _target_: torchvision.transforms.v2.CenterCrop
          size: 224

batch_size: 12
num_workers: 8
pin_memory: True
